{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pre_processing as pp\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pp.get_files(\"/Users/azamkhan/github/pdiot-practical/pdiot-data/2020/\")\n",
    "data = pp.get_data(\"Chest_Left\", files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, tgts, students = pp.get_data_by_datapoints(data, points_wanted = 50)\n",
    "tgts = pp.convert_targets(tgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data, targets, student_data, student_targets = pp.leave_one_out(data, tgts, students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5879518072289157\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(cleaned_data, targets)\n",
    "score = clf.score(student_data, student_targets)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9407, 3, 50)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestep = 50\n",
    "x_train = np.array([[c[0:timestep], c[timestep:2*timestep], c[2*timestep:3*timestep]] for c in cleaned_data])\n",
    "x_test = np.array([[c[0:timestep], c[timestep:2*timestep], c[2*timestep:3*timestep]] for c in student_data])\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = targets\n",
    "y_test = student_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9407, 3, 50, 1)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50, 1)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, LSTM, TimeDistributed\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Conv1D, MaxPooling2D, MaxPooling1D, ConvLSTM2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow import keras\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (2,2), activation='relu', input_shape = x_train[0].shape))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32, (2,2), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(14, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9407 samples, validate on 415 samples\n",
      "Epoch 1/5\n",
      "9407/9407 [==============================] - 22s 2ms/sample - loss: 1.6368 - accuracy: 0.4520 - val_loss: 0.7899 - val_accuracy: 0.7976\n",
      "Epoch 2/5\n",
      "9407/9407 [==============================] - 23s 2ms/sample - loss: 1.1942 - accuracy: 0.5729 - val_loss: 0.6386 - val_accuracy: 0.8627\n",
      "Epoch 3/5\n",
      "9407/9407 [==============================] - 22s 2ms/sample - loss: 1.0387 - accuracy: 0.6126 - val_loss: 0.5431 - val_accuracy: 0.8843\n",
      "Epoch 4/5\n",
      "9407/9407 [==============================] - 21s 2ms/sample - loss: 0.9809 - accuracy: 0.6367 - val_loss: 0.5954 - val_accuracy: 0.7566\n",
      "Epoch 5/5\n",
      "9407/9407 [==============================] - 21s 2ms/sample - loss: 0.9422 - accuracy: 0.6544 - val_loss: 0.5310 - val_accuracy: 0.7783\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=5, batch_size = 16, validation_data = (x_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN using L2 w/wo Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (2,2), activation='relu', input_shape = x_train[0].shape, kernel_regularizer=l2(0.000001), bias_regularizer=l2(0.000001)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32, (2,2), activation='relu', kernel_regularizer=l2(0.000001), bias_regularizer=l2(0.000001)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu', kernel_regularizer=l2(0.000001), bias_regularizer=l2(0.000001)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(14, activation='softmax', kernel_regularizer=l2(0.000001), bias_regularizer=l2(0.000001)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9407 samples, validate on 415 samples\n",
      "Epoch 1/7\n",
      "9407/9407 [==============================] - 24s 3ms/sample - loss: 1.6374 - accuracy: 0.4529 - val_loss: 0.8002 - val_accuracy: 0.7783\n",
      "Epoch 2/7\n",
      "9407/9407 [==============================] - 22s 2ms/sample - loss: 1.2137 - accuracy: 0.5679 - val_loss: 0.6806 - val_accuracy: 0.7904\n",
      "Epoch 3/7\n",
      "9407/9407 [==============================] - 22s 2ms/sample - loss: 1.0879 - accuracy: 0.6068 - val_loss: 0.6080 - val_accuracy: 0.8289\n",
      "Epoch 4/7\n",
      "9407/9407 [==============================] - 23s 2ms/sample - loss: 1.0133 - accuracy: 0.6269 - val_loss: 0.5761 - val_accuracy: 0.8482\n",
      "Epoch 5/7\n",
      "9407/9407 [==============================] - 22s 2ms/sample - loss: 0.9663 - accuracy: 0.6368 - val_loss: 0.6315 - val_accuracy: 0.7904\n",
      "Epoch 6/7\n",
      "9407/9407 [==============================] - 22s 2ms/sample - loss: 0.9369 - accuracy: 0.6495 - val_loss: 0.5217 - val_accuracy: 0.8771\n",
      "Epoch 7/7\n",
      "9407/9407 [==============================] - 22s 2ms/sample - loss: 0.8974 - accuracy: 0.6633 - val_loss: 0.5551 - val_accuracy: 0.7639\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=7, batch_size = 16, validation_data = (x_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D-CNN With LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape = (None, 3, 50))))\n",
    "#model.add(TimeDistributed(Dropout(0.1)))\n",
    "\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "#model.add(TimeDistributed(Dropout(0.2)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(14, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9407 samples, validate on 415 samples\n",
      "Epoch 1/5\n",
      "9407/9407 [==============================] - 75s 8ms/sample - loss: 1.3563 - accuracy: 0.5326 - val_loss: 0.7101 - val_accuracy: 0.6795\n",
      "Epoch 2/5\n",
      "9407/9407 [==============================] - 84s 9ms/sample - loss: 0.9187 - accuracy: 0.6695 - val_loss: 0.6372 - val_accuracy: 0.7952\n",
      "Epoch 3/5\n",
      "9407/9407 [==============================] - 71s 8ms/sample - loss: 0.7555 - accuracy: 0.7291 - val_loss: 0.6286 - val_accuracy: 0.7687\n",
      "Epoch 4/5\n",
      "9407/9407 [==============================] - 79s 8ms/sample - loss: 0.6503 - accuracy: 0.7642 - val_loss: 0.7266 - val_accuracy: 0.7663\n",
      "Epoch 5/5\n",
      "9407/9407 [==============================] - 69s 7ms/sample - loss: 0.5804 - accuracy: 0.7929 - val_loss: 0.7207 - val_accuracy: 0.6940\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=5, batch_size = 16, validation_data = (x_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Model to TF Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float model size = 2667KBs.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_float_model = converter.convert()\n",
    "\n",
    "float_model_size = len(tflite_float_model) / 1024\n",
    "print('Float model size = %dKBs.' % float_model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`har.tflite` has been downloaded\n"
     ]
    }
   ],
   "source": [
    "f = open('har.tflite', \"wb\")\n",
    "f.write(tflite_float_model)\n",
    "f.close()\n",
    "\n",
    "print('`har.tflite` has been downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "lx_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "lx_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lx_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_22 (LSTM)               (None, 3, 100)            60400     \n",
      "_________________________________________________________________\n",
      "flatten_44 (Flatten)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 14)                1414      \n",
      "=================================================================\n",
      "Total params: 91,914\n",
      "Trainable params: 91,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add((LSTM(100, return_sequences=True, input_shape = (3,50), kernel_regularizer=l2(0.000001), bias_regularizer=l2(0.000001))))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu', kernel_regularizer=l2(0.000001), bias_regularizer=l2(0.000001)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(14, activation='softmax', kernel_regularizer=l2(0.000001), bias_regularizer=l2(0.000001)))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9407 samples, validate on 415 samples\n",
      "Epoch 1/10\n",
      "9407/9407 [==============================] - 26s 3ms/sample - loss: 1.6986 - accuracy: 0.4287 - val_loss: 1.2229 - val_accuracy: 0.5590\n",
      "Epoch 2/10\n",
      "9407/9407 [==============================] - 18s 2ms/sample - loss: 1.3686 - accuracy: 0.5167 - val_loss: 1.1568 - val_accuracy: 0.6096\n",
      "Epoch 3/10\n",
      "9407/9407 [==============================] - 22s 2ms/sample - loss: 1.2626 - accuracy: 0.5532 - val_loss: 1.2271 - val_accuracy: 0.6096\n",
      "Epoch 4/10\n",
      "9407/9407 [==============================] - 20s 2ms/sample - loss: 1.1653 - accuracy: 0.5838 - val_loss: 1.0778 - val_accuracy: 0.6482\n",
      "Epoch 5/10\n",
      "9407/9407 [==============================] - 29s 3ms/sample - loss: 1.0820 - accuracy: 0.6151 - val_loss: 1.1985 - val_accuracy: 0.6458\n",
      "Epoch 6/10\n",
      "9407/9407 [==============================] - 23s 2ms/sample - loss: 1.0186 - accuracy: 0.6320 - val_loss: 1.2185 - val_accuracy: 0.6145\n",
      "Epoch 7/10\n",
      "9407/9407 [==============================] - 27s 3ms/sample - loss: 0.9642 - accuracy: 0.6507 - val_loss: 1.0481 - val_accuracy: 0.6434\n",
      "Epoch 8/10\n",
      "9407/9407 [==============================] - 33s 4ms/sample - loss: 0.9319 - accuracy: 0.6593 - val_loss: 1.0713 - val_accuracy: 0.6337\n",
      "Epoch 9/10\n",
      "9407/9407 [==============================] - 23s 2ms/sample - loss: 0.9087 - accuracy: 0.6741 - val_loss: 1.0583 - val_accuracy: 0.6169\n",
      "Epoch 10/10\n",
      "9407/9407 [==============================] - 25s 3ms/sample - loss: 0.8799 - accuracy: 0.6813 - val_loss: 1.3970 - val_accuracy: 0.5639\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(lx_train, y_train, epochs=10, batch_size=16, validation_data = (lx_test, y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
